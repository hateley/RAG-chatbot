{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf2yh1XVovlyWa16ODlWd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hateley/RAG-chatbot/blob/main/rag_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Question and Answer system that uses RAG from drug trail information on Epkinly and Polivy. This system relies primarily on LangChain."
      ],
      "metadata": {
        "id": "0agTTRe0H3Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install libraries\n",
        "\n",
        "**We need:**\n",
        "* **langchain**: This is a library for GenAI. We'll use it to chain together different language models and components for our chatbot.\n",
        "* **openai**: This is the official OpenAI Python client. We'll use it to interact with the OpenAI API and generate responses for our chatbot.\n",
        "* **pinecone-client**: This is the official Pinecone Python client. We'll use it to interact with the Pinecone API and store our chatbot's knowledge base in a vector database."
      ],
      "metadata": {
        "id": "bK2HuJjiIT1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install necessary libraries\n",
        "!pip install -qU \\\n",
        "    langchain==0.0.354 \\\n",
        "    langchain-openai \\\n",
        "    openai==1.6.1 \\\n",
        "    pinecone-client==3.1.0 \\\n",
        "    tiktoken==0.5.2"
      ],
      "metadata": {
        "id": "bXkxrcG6H20E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make a simple chatbot first"
      ],
      "metadata": {
        "id": "R7vl3irqJ_AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize the ChatOpenAI object\n",
        "\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"YOUR_API_KEY\"\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    model='gpt-3.5-turbo'\n",
        ")"
      ],
      "metadata": {
        "id": "sCeWN6DjIIEY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
        "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
        "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
        "]"
      ],
      "metadata": {
        "id": "-DdvsFQQJyQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}