{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the raw scraped webpages\n",
    "\n",
    "# Define the list of allowed URLs (whitelist)\n",
    "allowed_urls = [\n",
    "    \"https://www.polivy-hcp.com/newly-diagnosed/rchp/efficacy/trial-results.html\",\n",
    "    \"https://www.polivy-hcp.com/newly-diagnosed/rchp/safety/important-safety-information.html\",\n",
    "    \"https://www.polivy-hcp.com/newly-diagnosed/rchp/safety/summary.html\",\n",
    "    \"https://www.polivy-hcp.com/newly-diagnosed/rchp/efficacy/polarix-trial.html#trial-design\",\n",
    "    \"https://www.epkinlyhcp.com/dlbcl/study-design\",\n",
    "    \"https://www.epkinlyhcp.com/dlbcl/clinical-trial-results\",\n",
    "    \"https://www.epkinlyhcp.com/important-safety-information\",\n",
    "    \"https://www.epkinlyhcp.com/dlbcl/adverse-reactions\"\n",
    "]\n",
    "\n",
    "# Grab the HTML using Selenium and extract text with beautifulsoup\n",
    "def parse_selenium(url):\n",
    "    try:\n",
    "        driver = webdriver.Chrome()  # preferred browser\n",
    "        driver.get(url)\n",
    "\n",
    "        # Get rendered HTML content\n",
    "        html_content = driver.page_source\n",
    "        driver.quit()\n",
    "\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # Extract text from the page\n",
    "        text = soup.get_text()\n",
    "\n",
    "        # Create a filename based on the URL\n",
    "        filename = url.split('/')[2].rstrip(\"-hcp.com\").lstrip(\"www.\") + \"_\" + url.split('/')[-1].rstrip(\".html\") + '.txt'\n",
    "\n",
    "        # Write raw text to a file\n",
    "        if not os.path.exists(\"text/\"):\n",
    "            os.mkdir(\"text/\")\n",
    "            \n",
    "        with open(\"text/\"+filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching url: {url}, {e}\")\n",
    "\n",
    "# Iterate through the URLs and parse each one\n",
    "for url in allowed_urls:\n",
    "    parse_selenium(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polivy_summary.txt\n",
      "epkinly_study-design.txt\n",
      "polivy_polarix-trial.html#trial-design.txt\n",
      "polivy_trial-results.txt\n",
      "epkinly_important-safety-information.txt\n",
      "epkinly_clinical-trial-results.txt\n",
      "epkinly_adverse-reactions.txt\n",
      "polivy_important-safety-information.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polivy_summary.txt</td>\n",
       "      <td>polivy_summary.txt.  POLIVY® (polatuzumab vedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epkinly_study-design.txt</td>\n",
       "      <td>epkinly_study-design.txt.                 DLBC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polivy_polarix-trial.html#trial-design.txt</td>\n",
       "      <td>polivy_polarix-trial.html#trial-design.txt.  P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>polivy_trial-results.txt</td>\n",
       "      <td>polivy_trial-results.txt.  POLARIX Trial Resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>epkinly_important-safety-information.txt</td>\n",
       "      <td>epkinly_important-safety-information.txt.     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        fname  \\\n",
       "0                          polivy_summary.txt   \n",
       "1                    epkinly_study-design.txt   \n",
       "2  polivy_polarix-trial.html#trial-design.txt   \n",
       "3                    polivy_trial-results.txt   \n",
       "4    epkinly_important-safety-information.txt   \n",
       "\n",
       "                                                text  \n",
       "0  polivy_summary.txt.  POLIVY® (polatuzumab vedo...  \n",
       "1  epkinly_study-design.txt.                 DLBC...  \n",
       "2  polivy_polarix-trial.html#trial-design.txt.  P...  \n",
       "3  polivy_trial-results.txt.  POLARIX Trial Resul...  \n",
       "4  epkinly_important-safety-information.txt.     ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fast cleanup of raw text \n",
    "\n",
    "# helper function to remove all the newlines that mess up embeddings\n",
    "def remove_newlines(txt):\n",
    "    txt = txt.str.replace('\\n', ' ')\n",
    "    txt = txt.str.replace('\\\\n', ' ')\n",
    "    txt = txt.str.replace('  ', ' ')\n",
    "    txt = txt.str.replace('  ', ' ')\n",
    "    return txt\n",
    "\n",
    "# Create a list to store the text files\n",
    "texts=[]\n",
    "\n",
    "# Get all the text files in the text directory\n",
    "for file in os.listdir(\"text/\"):\n",
    "    print(file)\n",
    "\n",
    "    # Open the file and read the text\n",
    "    with open(\"text/\"+ file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        texts.append((file, text))\n",
    "\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(texts, columns = ['fname', 'text'])\n",
    "\n",
    "# Remove the newlines\n",
    "df['text'] = df.fname + \". \" + remove_newlines(df.text)\n",
    "\n",
    "# save scraped dataframe as a tsv\n",
    "\n",
    "if not os.path.exists(\"processed\"):\n",
    "    os.mkdir(\"processed\")\n",
    "        \n",
    "df.to_csv('processed/scraped.tsv', index=False, sep='\\t')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "05f34a34d73b71652304030c1097be3a5720ea2447153dd6542d145a26b73181"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
